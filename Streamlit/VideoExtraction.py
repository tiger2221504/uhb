import streamlit as st
import tempfile
import os
import subprocess
import json
import re
import openai
from moviepy.editor import VideoFileClip
import time
# os.system("apt-get update && apt-get install -y ffmpeg")

# ==é–¢æ•°==
# é€šçŸ¥ã‚’å‡ºã™
def notification(text):
    md = f"""
    <script>
    if ("Notification" in window) {{
      if (Notification.permission === "granted") {{
        new Notification('{text}');
      }} else if (Notification.permission !== "denied") {{
        Notification.requestPermission().then(function (permission) {{
          if (permission === "granted") {{
            new Notification('{text}');
          }}
        }});
      }}
    }}
    </script>
    """
    st.markdown(md, unsafe_allow_html=True)
    
# å‹•ç”»ã®é•·ã•å–å¾—
def get_video_duration(video_path):
    result = subprocess.run(
        [
            "ffprobe", "-v", "error", "-show_entries",
            "format=duration", "-of", "json", video_path
        ],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT
    )
    info = json.loads(result.stdout)
    return float(info["format"]["duration"])

# ã‚¯ãƒªãƒƒãƒ—çµåˆ
def concat_clips_ffmpeg(clip_filenames, output_path):
    input_args = []
    for clip in clip_filenames:
        input_args.extend(["-i", clip])

    filter_parts = []
    for i in range(len(clip_filenames)):
        filter_parts.append(f"[{i}:v:0][{i}:a:0]")
    filter_concat = "".join(filter_parts)
    filter_complex = f"{filter_concat}concat=n={len(clip_filenames)}:v=1:a=1[outv][outa]"

    cmd = [
        "ffmpeg",
        "-y",
        *input_args,
        "-filter_complex", filter_complex,
        "-map", "[outv]",
        "-map", "[outa]",
        "-c:v", "libx264",
        "-preset", "ultrafast",
        "-crf", "28",
        "-c:a", "aac",
        "-b:a", "192k",
        output_path
    ]

    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    # st.write(result.stdout)  # ffmpegã®ãƒ­ã‚°ã‚’Streamlitã«è¡¨ç¤º

# éŸ³å£°æœ‰ç„¡
def has_audio_stream(video_path):
    result = subprocess.run(
        [
            "ffprobe", "-v", "error", "-select_streams", "a",
            "-show_entries", "stream=index", "-of", "default=noprint_wrappers=1:nokey=1",
            video_path
        ],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True
    )
    return result.stdout.strip() != ""

# ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆä½“
def merge_overlapping_segments(segments, tolerance=0.01):
    sorted_segments = sorted(segments, key=lambda x: x["start"])
    merged = []
    for seg in sorted_segments:
        if not merged:
            merged.append(seg)
        else:
            last = merged[-1]
            if last["end"] + tolerance >= seg["start"]:
                last["end"] = max(last["end"], seg["end"])
            else:
                merged.append(seg)
    return merged

# å‹•ç”»ç”Ÿæˆ
def process_segment(segments, video_path, file_name):
    duration = get_video_duration(video_path)
    for seg in segments:
        if seg["start"] < 0 or seg["end"] > duration:
            st.error(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{seg}ãŒå‹•ç”»å°º({duration:.2f}s)ã‚’è¶…ãˆã¦ã„ã¾ã™")
            return
        if seg["start"] >= seg["end"]:
            st.error(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸æ­£: start({seg['start']}) >= end({seg['end']})")
            return
    segments = merge_overlapping_segments(segments)
    sorted_segments = sorted(segments, key=lambda x: x["start"])
    for i in range(len(sorted_segments) - 1):
        cur = sorted_segments[i]
        next_ = sorted_segments[i + 1]
        if cur["end"] >= next_["start"]:
            st.error(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé‡è¤‡: [{cur['start']}ã€œ{cur['end']}] ã¨ [{next_['start']}ã€œ{next_['end']}]")
            return
    if not os.path.exists(video_path):
        st.error(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
        return

    clip_filenames = []
    for i, seg in enumerate(segments):
        output = f"clip_{i}.mp4"
        clip_filenames.append(output)
        has_audio = has_audio_stream(video_path)
        if has_audio:
            audio_filter = (
                f"[0:a]atrim=start={seg['start']}:end={seg['end']},asetpts=PTS-STARTPTS[a];"
            )
            audio_map = ["-map", "[a]"]
        else:
            audio_filter = ""
            audio_map = []
        filter_complex = (
            f"[0:v]trim=start={seg['start']}:end={seg['end']},setpts=PTS-STARTPTS[v];"
            f"{audio_filter}"
            f"[v]scale=1280:720:force_original_aspect_ratio=decrease,"
            f"pad=1280:720:(ow-iw)/2:(oh-ih)/2[outv]"
        )
        cmd = [
            "ffmpeg", "-y", "-i", video_path,
            "-filter_complex", filter_complex,
            "-map", "[outv]", *audio_map,
            "-c:v", "libx264", "-preset", "ultrafast", "-crf", "28",
            "-c:a", "aac", "-b:a", "192k", output
        ]
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
        # st.write(result.stdout)
    clip_files = [f"clip_{i}.mp4" for i in range(len(segments))]
    output_path = f"{file_name}.mp4"
    concat_clips_ffmpeg(clip_files, output_path)
    for clip in clip_filenames:
        if os.path.exists(clip):
            os.remove(clip)
    return output_path

# è¤‡æ•°å‹•ç”»
def process_multiple_videos(video_configs, video_path, output_file_name):
    output_files = []
    for i, config in enumerate(video_configs):
        st.markdown(f"### å‹•ç”»{i+1}")
        file_name = f"{output_file_name}{i+1}"
        msg = st.empty()
        msg.info(f"å‹•ç”»{i+1}ã‚’ç”Ÿæˆä¸­â€¦")
        output_file = process_segment(config["segments"], video_path, file_name)
        if output_file and os.path.exists(output_file):
            msg.empty()
            with open(output_file, "rb") as f:
                video_bytes = f.read()

            st.video(video_bytes)

            c1, c2 = st.columns(2)
            # è¦‹å‡ºã—1
            with c1:
                h1 = config['headline'][0]
                st.write(f"å‹•ç”»{i+1} è¦‹å‡ºã—1è¡Œç›®:{h1}")
                st.components.v1.html(
                    f"""
                    <div style="display: flex; align-items: center;">
                        <textarea id="text-areaA-{i}" style="width:0;height:0;opacity:0;position:absolute;">{h1}</textarea>
                        <button onclick="copyTextA_{i}()" style="height:28px;font-size:0.9em;">ã‚³ãƒ”ãƒ¼</button>
                        <span id="copy-messageA-{i}" style="color:green; display:none; font-size:0.9em; margin-left:6px;">â˜‘ã‚³ãƒ”ãƒ¼</span>
                    </div>
                    <script>
                    function copyTextA_{i}() {{
                        var text = document.getElementById('text-areaA-{i}').value;
                        navigator.clipboard.writeText(text).then(function() {{
                            document.getElementById('copy-messageA-{i}').style.display = 'inline';
                            setTimeout(function() {{
                                document.getElementById('copy-messageA-{i}').style.display = 'none';
                            }}, 1500);
                        }});
                    }}
                    </script>
                    """,
                    height=38,
                )
            
            # è¦‹å‡ºã—2
            with c2:
                h2 = config['headline'][1]
                st.write(f"å‹•ç”»{i+1} è¦‹å‡ºã—2è¡Œç›®:{h2}")
                st.components.v1.html(
                    f"""
                    <div style="display: flex; align-items: center;">
                        <textarea id="text-areaB-{i}" style="width:0;height:0;opacity:0;position:absolute;">{h2}</textarea>
                        <button onclick="copyTextB_{i}()" style="height:28px;font-size:0.9em;">ã‚³ãƒ”ãƒ¼</button>
                        <span id="copy-messageB-{i}" style="color:green; display:none; font-size:0.9em; margin-left:6px;">â˜‘ã‚³ãƒ”ãƒ¼</span>
                    </div>
                    <script>
                    function copyTextB_{i}() {{
                        var text = document.getElementById('text-areaB-{i}').value;
                        navigator.clipboard.writeText(text).then(function() {{
                            document.getElementById('copy-messageB-{i}').style.display = 'inline';
                            setTimeout(function() {{
                                document.getElementById('copy-messageB-{i}').style.display = 'none';
                            }}, 1500);
                        }});
                    }}
                    </script>
                    """,
                    height=38,
                )
                
            st.download_button(
                label=f"å‹•ç”»{i+1}ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=video_bytes,
                file_name=output_file,
                mime="video/mp4"
            )
            
            output_files.append(output_file)
        else:
            msg.empty()
            st.error(f"å‹•ç”»{i+1}ã®ç”Ÿæˆã«å¤±æ•—")
    notification("å…¨ã¦ã®å‹•ç”»ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    return output_files

# GPTå‡ºåŠ›ã‹ã‚‰JSONæŠ½å‡º
def extract_json(gpt_output):
    match = re.search(r"(\[\s*{.*}\s*\])", gpt_output, re.DOTALL)
    if not match:
        st.error("JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        st.write(gpt_output)
        return None
    raw_json = match.group(1)
    cleaned_json = (
        raw_json.replace("â€œ", '"').replace("â€", '"')
        .replace("â€˜", "'").replace("â€™", "'").strip()
    )
    try:
        return json.loads(cleaned_json)
    except json.JSONDecodeError as e:
        st.error("JSONã®ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼")
        st.write(cleaned_json)
        return None

# JSONéƒ¨åˆ†ã ã‘æŠ½å‡º
def extract_json(gpt_output):
    match = re.search(r"(\[\s*{.*}\s*\])", gpt_output, re.DOTALL)
    if not match:
        return None
    raw_json = match.group(1)
    cleaned_json = (
        raw_json
        .replace("â€œ", '"')
        .replace("â€", '"')
        .replace("â€˜", "'")
        .replace("â€™", "'")
        .strip()
    )
    try:
        return json.loads(cleaned_json)
    except json.JSONDecodeError:
        return None

# ã“ã“ã‹ã‚‰ãƒ¡ã‚¤ãƒ³
def main():
    USER_CREDENTIALS = st.secrets["USER_CREDENTIALS"]
    api_key = ""
    gpt_model = "gpt-4.1"
    uploaded_file = None
    temp_video_path = None
    video_configs = None

    st.set_page_config(page_title="å‹•ç”»åˆ‡ã‚Šå–ã‚Šã‚¢ãƒ—ãƒª",page_icon="ğŸ¬", layout="wide")
    st.title("å‹•ç”»åˆ‡ã‚Šå–ã‚Šã‚¢ãƒ—ãƒªâœ‚ï¸")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ä¿æŒ
    if "logged_in" not in st.session_state:
        st.session_state.logged_in = False
    if "username" not in st.session_state:
        st.session_state.username = ""
    if "api_key" not in st.session_state:
        st.session_state.api_key = ""
    
    try:
        msg = st.sidebar.empty()
        msg2 = st.empty()
        
        if not st.session_state.logged_in:
            login_area = st.sidebar.empty()
            with login_area.container():
                st.header("ãƒ­ã‚°ã‚¤ãƒ³")
                username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
                password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
                login_button = st.button("ãƒ­ã‚°ã‚¤ãƒ³")
                
                # èªè¨¼å‡¦ç†
                if login_button:
                    user_info = USER_CREDENTIALS.get(username)
                    if user_info and user_info["password"] == password:
                        st.session_state.logged_in = True
                        st.session_state.username = username
                        st.session_state.api_key = user_info["api_key"]
                        api_key = st.session_state.api_key
                        login_area.empty() # ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’æ¶ˆã™
                        msg.success("ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸ")
                        time.sleep(2)
                        msg.empty()
                        st.rerun() # ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’åæ˜ ã™ã‚‹ãŸã‚ã«å†å®Ÿè¡Œ
                    elif (not user_info) or (not user_info["password"]):
                        st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã©ã¡ã‚‰ã‚‚å…¥åŠ›ã—ã¦ãã ã•ã„")
                    else:
                        st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
        else:
            # ãƒ­ã‚°ã‚¤ãƒ³å¾Œã«è¡¨ç¤º
            user_info = USER_CREDENTIALS[st.session_state.username]
            loginmessage = f"ğŸ‘¤ **{st.session_state.username}**ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ä¸­"
            st.sidebar.markdown(loginmessage)
            notification(loginmessage)
            api_key = st.session_state.api_key
            if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
                st.session_state.logged_in = False
                st.session_state.username = ""
                st.session_state.api_key = ""
                st.rerun()  # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆå¾Œã«ç”»é¢ã‚’æ›´æ–°

        # --- å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
        if not st.session_state.logged_in:
            st.warning("ğŸ‘ˆã¾ãšã¯ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„")
        if st.session_state.logged_in:
            st.header("â– å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            msg2.success("å‹•ç”»ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—ã§èª­ã¿è¾¼ã¿ã§ãã¾ã™ï¼")
            uploaded_file = st.file_uploader(
                "ã“ã“ã«å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã€ã¾ãŸã¯ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠ",
                type=["mp4"],
                accept_multiple_files=False
            )
            if uploaded_file is None:
                st.warning("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                st.stop()
            else:
                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚åˆ»ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
                prev_upload_time = st.session_state.get("upload_time")
                msg3 = st.empty()
                # æ–°ã—ã„å‹•ç”»ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå ´åˆã ã‘ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒªã‚»ãƒƒãƒˆ
                now_upload_time = str(int(time.time()))  # ç§’å˜ä½ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆæ–‡å­—åˆ—åŒ–ï¼‰
                if not prev_upload_time or st.session_state.get("uploaded_file_obj") != uploaded_file:
                    st.session_state["upload_time"] = now_upload_time
                    st.session_state["uploaded_file_obj"] = uploaded_file
                    st.session_state["video_configs"] = None
                    st.session_state["transcript"] = None
                msg2.empty()
                msg3.success("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                video_configs = None
                base_file_name = os.path.splitext(os.path.basename(uploaded_file.name))[0]
                base_file_name_short = base_file_name[:50]
                output_file_name = f"{base_file_name_short}_{st.session_state['upload_time']}_"
                temp_video = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                temp_video.write(uploaded_file.getbuffer())
                temp_video_path = temp_video.name
                temp_video.close()
        
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰ã‚ã£ãŸã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
                if (
                    "uploaded_file_name" not in st.session_state or
                    st.session_state.uploaded_file_name != uploaded_file.name
                ):
                    st.session_state.uploaded_file_name = uploaded_file.name
                    st.session_state.transcript = None  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
    
            if "transcript" not in st.session_state or st.session_state.transcript is None:
                # Whisperã§éŸ³å£°æŠ½å‡ºï¼†èªè­˜
                audio_tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                video = VideoFileClip(temp_video_path)
                video.audio.write_audiofile(audio_tmp.name, logger=None)
                audio_tmp.close()
                msg3.empty()
                with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­â€¦ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„"):
                    client = openai.OpenAI(api_key=api_key)
                    with open(audio_tmp.name, "rb") as audio_file:
                        transcript = client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file,
                            response_format="verbose_json",
                            language="ja"
                        )
                    os.remove(audio_tmp.name)
                    st.session_state.transcript = transcript
            else:
                transcript = st.session_state.transcript
    
            # ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
            texts = ""
            for i, segment in enumerate(transcript.segments):
                texts += f"{segment.text}\n"
            with st.expander("éŸ³å£°èªè­˜çµæœã‚’è¡¨ç¤ºï¼ˆã‚¯ãƒªãƒƒã‚¯ã§é–‹é–‰ï¼‰", expanded=False):
                st.text_area("", texts, height=250)
            st.markdown("---")
        
        # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã‚‹
        segment_texts = ""
        for i, segment in enumerate(transcript.segments):
            start = segment.start
            end = segment.end
            text = segment.text
        
            segment_texts += (f"[Segment {i}] {start:.2f}s - {end:.2f}s\n")
            segment_texts += (f"Text: {text}\n")
            segment_texts += ("\n")
        
        # ChatGPTã§åˆ‡ã‚Šå‡ºã—æ¡ˆç”Ÿæˆ
        with st.spinner("AIãŒåˆ‡ã‚Šå‡ºã—ç®‡æ‰€ã‚’è€ƒãˆä¸­â€¦ğŸ¤”"):
            prompt = """
ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€ä¸ãˆã‚‰ã‚ŒãŸéŸ³å£°èªè­˜çµæœã‹ã‚‰å‹•ç”»ã®æ§‹æˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€æ¦‚è¦ã€‘
é•·å°ºã®å‹•ç”»ã«è¦–è´è€…ã‚’èª˜å°ã™ã‚‹ãŸã‚ã®Shortå‹•ç”»ã‚’ä½œæˆã—ã¾ã™ã€‚
1åˆ†ä»¥å†…ã®â€œäºˆå‘Šç·¨å‹•ç”»â€ã‚’æ„è­˜ã—ã¦ã€å‹•ç”»ã‚’åˆ‡ã‚Šå–ã‚‹ç®‡æ‰€ã‚’æ±ºã‚ã¦ãã ã•ã„ã€‚
ãªã‚‹ã¹ããŸãã•ã‚“åˆ†å‰²ã—ã€è¦‹ã‚„ã™ã„å‹•ç”»ã‚’æ„è­˜ã—ã¾ã™ã€‚

ã€ç”Ÿæˆå†…å®¹ã€‘
â‘ headline
- è¦‹å‡ºã—ã¨ãªã‚‹æ–‡ã‚’æ—¥æœ¬èªã§2ã¤ç”Ÿæˆ
- ã©ã¡ã‚‰ã‚‚13æ–‡å­—ç¨‹åº¦ã§ä½œæˆ
- ã€Œç¶šããŒè¦‹ãŸããªã‚Šãã†ãªè¦‹å‡ºã—ã€ã‚’æ„è­˜ã™ã‚‹
â€»ã€Œ**ã¨ã¯â€¦ã€ã€Œãªãœ**ï¼Ÿã€ã®ã‚ˆã†ãªæ–‡æœ«ãŒç¶šããŒè¦‹ãŸããªã‚Šãã†ãªè¦‹å‡ºã—ã€‚
- 2ã¤ã®è¦‹å‡ºã—ã«å…±é€šã®å˜èªã‚„åŒã˜æ„å‘³ã®è¨€è‘‰ã¯ä½¿ç”¨ã—ãªã„
- â€œæ¼¢å­—ã®ã¿â€ã®è¦‹å‡ºã—ã¯é¿ã‘ã‚‹
- çµµæ–‡å­—ã‚„ç‰¹æ®Šæ–‡å­—ã¯ä½¿ç”¨ç¦æ­¢
- è¨˜å·ã¯å…¨è§’ã®ã‚‚ã®ã‚’ä½¿ç”¨ã™ã‚‹
- æ•°å­—ãƒ»ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãƒ»ç©ºç™½ã¯åŠè§’ã®ã‚‚ã®ã‚’ä½¿ç”¨ã™ã‚‹
- éŸ³å£°èªè­˜çµæœã«èª¤å­—ãŒã‚ã‚‹ã¨åˆ¤æ–­ã—ãŸå ´åˆã¯æ­£ã—ã„å­—ã«ç›´ã—ã¦å‡ºåŠ›ã™ã‚‹ï¼ˆä¾‹ï¼šã€Œãƒ‰ãƒ¼ãƒŸãƒ³ã€ï¼ã€Œé“æ°‘ã€,ã€Œå¯ä¸Šã’ã€ï¼ã€Œå€¤ä¸Šã’ã€ ãªã©ï¼‰
ä¾‹1ï¼š["â€œã¨ã£ã•ã«è¹´ã‚Šâ€ã§åæ’ƒ", "ç©ºæ‰‹å®¶ãŒé­é‡ã—ãŸã®ã¯â€¦"]
ä¾‹2ï¼š["ãƒ€ãƒ–ãƒ«åŒå­ãƒãƒã«å¯†ç€", "å¿™ã—ã„æœ ä¹—ã‚Šåˆ‡ã‚Œã‚‹ï¼Ÿ"]
â‘¡segments
- å‹•ç”»ã®INç‚¹ã¨OUTç‚¹ã‚’æ±ºã‚ã‚‹
- 1ã¤ã§ã‚‚ã€è¤‡æ•°å…¥ã£ã¦ã‚‚è‰¯ã„
- segmetã®textã®é€”ä¸­ã§åˆ‡ã‚‹ã“ã¨ã¯é¿ã‘ã‚‹
- ç–‘å•ã‚’æŠ•ã’ã‹ã‘ã‚‹å½¢ã®ã‚»ãƒªãƒ•ã§çµ‚ã‚ã‚‹ã¨è‰¯ã„
- é•ã†ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¹‹ã’ã¦1ã¤ã®æ–‡ç« ã«ã—ã¦ã¯ã„ã‘ãªã„
- 1ç§’æœªæº€ã®ã‚«ãƒƒãƒˆã¯é¸ã°ãªã„ã‚ˆã†ã«ã™ã‚‹
- çµåˆã—ãŸéš›ã®åˆè¨ˆæ™‚é–“ã¯50ç§’ä»¥å†…ã«åã‚ã‚‹
- èãã‚„ã™ã„ã‚ˆã†ã«ç„¡å£°éƒ¨åˆ†ã‚‚æ•°ç§’å…¥ã‚Œã¦ä½™è£•ã‚’ã‚‚ã£ãŸæ™‚é–“è¨­å®šã«ã™ã‚‹
- ä¸€ç•ªæœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ã€1ç§’ç¨‹åº¦ä½™è£•ã‚’æŒãŸã›ã‚‹ã€‚ãŸã ã—ã€æ¬¡ã®éŸ³å£°ã«å…¥ã£ã¦ã—ã¾ã†å ´åˆã¯ã‚®ãƒªã‚®ãƒªã§åˆ‡ã‚‹ã€‚
ä¾‹1ï¼š[{"start": 10.5, "end": 20.8}]
ä¾‹2ï¼š[{"start": 63, "end": 70.2}, {"start": 81.2, "end": 90.3}, ...]
â‘¢font_colors
- "red", "orange", "yellow", "green", "cyan", "magenta", "lime", "white"ã®ä¸­ã‹ã‚‰2è‰²ã‚’æŒ‡å®š
- æ–‡å­—ã®èƒŒæ™¯ã¯çœŸã£é»’ã«ãªã‚‹ã“ã¨ã‚’æƒ³å®šã—ãŸã†ãˆã§ã€èª­ã¿ã‚„ã™ã•ã‚’è€ƒæ…®ã™ã‚‹
- 1è‰²ç›®ã¯åŸºæœ¬çš„ã«"red"ã«ã™ã‚‹(ãŸã ã—ã€å†…å®¹ã«ã‚ˆã£ã¦ä»–ã®è‰²ãŒã„ã„ã¨åˆ¤æ–­ã—ãŸå ´åˆã¯å¤‰æ›´ã—ã¦ã‚ˆã„)
- 2è‰²ç›®ã¯åŸºæœ¬çš„ã«"white"ã«ã™ã‚‹
- åŒã˜çµ„ã¿åˆã‚ã›ã®å‹•ç”»ãŒè¤‡æ•°ã§ãã¦ã‚‚æ§‹ã‚ãªã„

ã€å‡ºåŠ›ã®ãƒ«ãƒ¼ãƒ«ã€‘
- å‡ºåŠ›ã¯Pythonã®list[dict]å½¢å¼ã®JSONæ§‹é€ ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆkeyé †ã¯ headline â†’ segments â†’ font_colorsï¼‰
- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜å·ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„
- headlineã¯ãã‚Œãã‚Œ10æ–‡å­—ä»¥ä¸Š14æ–‡å­—ä»¥å†…ã®æ—¥æœ¬èªã§å¿…ãš2ã¤å…¥ã‚Œã¦ãã ã•ã„
- segments ã¯ start, end ã®ç§’æ•°ã‚’ floatå‹ã§å°æ•°ç¬¬1ä½ã¾ã§ã§æŒ‡å®šã—ã€éŸ³å£°ã«åŸºã¥ã„ã¦å†…å®¹ã®åˆ‡ã‚Œç›®ã‚’é©åˆ‡ã«è¨­å®šã—ã¦ãã ã•ã„
- å‡ºåŠ›ä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ç¦æ­¢ã€‚JSONä»¥å¤–ã®å‡ºåŠ›ï¼ˆèª¬æ˜æ–‡ã€è£œè¶³ã€ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å¤–ãªã©ï¼‰ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„
- ãƒªã‚¹ãƒˆã®ä¸­èº«ã®æ•°ï¼ˆæœ€çµ‚çš„ãªå‹•ç”»ã®æ•°ï¼‰ã¯5ã¤ä»¥ä¸Šã¨ã—ã¦ãã ã•ã„
- åŒã˜å ´é¢ã‚’é•ã†åˆ‡ã‚Šå£ã§åˆ‡ã‚Šå‡ºã—ã¦æ•°ã‚’å¢—ã‚„ã—ã¦ã‚‚è‰¯ã„

ã€å‡ºåŠ›å½¢å¼ã€‘
[
  {
    "headline": ["ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³1-1", "ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³1-2"],
    "segments": [{"start": ç§’æ•°, "end": ç§’æ•°}, {"start": ç§’æ•°, "end": ç§’æ•°}, ...],
    "font_colors": ["è‰²1-1", "è‰²1-2"]
  },
  {
    "headline": ["ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³2-1", "ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³2-2"],
    "segments": [{"start": ç§’æ•°, "end": ç§’æ•°}, {"start": ç§’æ•°, "end": ç§’æ•°}, ...],
    "font_colors": ["è‰²2-1", "è‰²2-2"]
  },
  â€¦ï¼ˆ3ã¤ä»¥ä¸Šç¶šã„ã¦ã‚‚è‰¯ã„ï¼‰
]

ã€éŸ³å£°èªè­˜çµæœã€‘
""" + segment_texts

            client = openai.OpenAI(api_key=api_key)
            if st.session_state.get("video_configs") is None:
                response = client.chat.completions.create(
                    model=gpt_model,
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ãƒ¬ãƒ“å±€ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹å‹•ç”»ã‚’ãƒãƒƒãƒˆé…ä¿¡ã™ã‚‹ãƒ—ãƒ­ã®ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7
                )
                gpt_output = response.choices[0].message.content
    
                video_configs = extract_json(gpt_output)
                st.session_state["video_configs"] = video_configs
            else:
                video_configs = st.session_state["video_configs"]
            
            if not video_configs:
                st.error("JSONæ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
    
            # å€™è£œãŒæ±ºã¾ã£ãŸã‚‰
            st.session_state["video_configs"] = video_configs
            msg4 = st.empty()
        if "video_configs" in st.session_state:
            video_configs = st.session_state["video_configs"]
            num_videos = len(video_configs)
            msg4.success(f"{num_videos}æœ¬ã®å€™è£œãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å‹•ç”»ã‚’åˆ‡ã‚Šå‡ºã—ã¾ã™ã€‚")

            # æ¡ˆã®å†…å®¹ã‚’ç¢ºèª
            for i, config in enumerate(video_configs):
                with st.expander(f"å€™è£œ {i+1}: {config['headline'][0]} ï¼ {config['headline'][1]}", expanded=False):
                    st.markdown("**åˆ‡ã‚Šå‡ºã—åŒºé–“ï¼ˆç§’ï¼‰**")
                    for seg in config['segments']:
                        st.markdown(
                            f"- â±ï¸ **{seg['start']:.1f}** ï½ **{seg['end']:.1f}**"
                        )
    
            with st.spinner("å‹•ç”»ã‚’åˆ‡ã‚Šå‡ºã—ä¸­â€¦"):
                process_multiple_videos(
                    video_configs, temp_video_path, output_file_name
                )
                msg4.empty()
            st.success("å‹•ç”»ãŒå®Œæˆã—ã¾ã—ãŸï¼")
            st.rerun()

    except Exception as e:
        err_msg = str(e)
        if "incorrect api key" in err_msg.lower() or "invalid_api_key" in err_msg.lower():
            st.error("è¨­å®šã•ã‚ŒãŸAPIã‚­ãƒ¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ­ã‚°ã‚¤ãƒ³ã—ãªãŠã—ã¦ãã ã•ã„ã€‚")
        elif "insufficient_quota" in err_msg.lower():
            st.error("ç™»éŒ²ã•ã‚ŒãŸAPIã‚­ãƒ¼ã®åˆ©ç”¨ä¸Šé™ã‚’è¶…ãˆã¾ã—ãŸã€‚Usage/Billingç”»é¢ã§æ®‹é«˜ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        elif "'invalid_request_error', 'param': None" in err_msg.lower():
            st.error("ãƒšãƒ¼ã‚¸æ›´æ–°å¾Œã€ãƒ­ã‚°ã‚¤ãƒ³ã—ãªãŠã—ã¦ãã ã•ã„")
        else:
            if st.session_state.logged_in:
                st.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == '__main__':
    main()
